{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rank', 'Nation', 'Gold', 'Silver', 'Bronze', 'Total']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandasql import sqldf\n",
    "\n",
    "\n",
    "def table_formater(df, seperator='|', col_data_split='', col_prefix='[HEAD]', row_prefix='[ROW]', permute_df=True, utterance=None):\n",
    "\n",
    "    # if permute_df and utterance is not None:\n",
    "    #     df = permuteDataFrame(df, utterance)['col reorder based on name overlaps']\n",
    "    \n",
    "    table_str = []\n",
    "    if col_prefix != '':\n",
    "        table_str.append(col_prefix + ': ' + seperator.join(df.columns.tolist()))\n",
    "    else:\n",
    "        table_str.append(seperator.join(df.columns.tolist()))\n",
    "        \n",
    "    if col_data_split != '':\n",
    "        table_str.append(col_data_split * len(table_str[-1]))\n",
    "    for i in range(df.shape[0]):\n",
    "        if row_prefix != '':\n",
    "            table_str.append(row_prefix + f' {i+1}: ' + seperator.join([str(i) for i in df.iloc[i].tolist()]))\n",
    "        else:\n",
    "            table_str.append(seperator.join([str(i) for i in df.iloc[i].tolist()]))\n",
    "    return '\\n'.join(table_str)\n",
    "\n",
    "\n",
    "\n",
    "latex_special_token = [\"!@#$%^&*()\"]\n",
    "\n",
    "def generate(text_list, attention_list, latex_file, color='red', rescale_value = False):\n",
    "    assert(len(text_list) == len(attention_list))\n",
    "    if rescale_value:\n",
    "        attention_list = rescale(attention_list)\n",
    "    word_num = len(text_list)\n",
    "    text_list = clean_word(text_list)\n",
    "    with open(latex_file,'w') as f:\n",
    "        f.write(r'''\\documentclass[varwidth]{standalone}\n",
    "\\special{papersize=210mm,297mm}\n",
    "\\usepackage{color}\n",
    "\\usepackage{tcolorbox}\n",
    "\\usepackage{CJK}\n",
    "\\usepackage{adjustbox}\n",
    "\\tcbset{width=0.9\\textwidth,boxrule=0pt,colback=red,arc=0pt,auto outer arc,left=0pt,right=0pt,boxsep=5pt}\n",
    "\\begin{document}\n",
    "\\begin{CJK*}{UTF8}{gbsn}'''+'\\n')\n",
    "        string = r'''{\\setlength{\\fboxsep}{0pt}\\colorbox{white!0}{\\parbox{0.9\\textwidth}{'''+\"\\n\"\n",
    "        for idx in range(word_num):\n",
    "            if '\\n' in text_list[idx]:\n",
    "                text_list[idx] = text_list[idx].replace('\\n', '\\\\\\\\')#.replace('|', '\\\\|')\n",
    "                suffix = '\\\\\\\\'\n",
    "            else:\n",
    "                suffix = ''\n",
    "            string += \"\\\\colorbox{%s!%s}{\"%(color, attention_list[idx])+\"\\\\strut \" + text_list[idx]+\"} \" + suffix + ' '\n",
    "        string += \"\\n}}}\"\n",
    "        f.write(string+'\\n')\n",
    "        f.write(r'''\\end{CJK*}\n",
    "\\end{document}''')\n",
    "\n",
    "def rescale(input_list, soft_max=False):\n",
    "    if soft_max:\n",
    "        x = np.array(input_list)\n",
    "        rescale = np.exp(x)/np.exp(x).sum()\n",
    "        scale_factor = 100 / np.max(rescale)\n",
    "        rescale *= scale_factor      \n",
    "    else:\n",
    "        the_array = np.asarray(input_list)\n",
    "        the_max = np.max(the_array)\n",
    "        the_min = np.min(the_array)\n",
    "        rescale = (the_array - the_min)/(the_max-the_min)\n",
    "        scale_factor = 100 / np.max(rescale)\n",
    "        rescale *= scale_factor      \n",
    "    print(\"rescaled to max: \", np.max(rescale), ', min: ', np.min(rescale), ', sum: ', np.sum(rescale))\n",
    "    return rescale.tolist()\n",
    "\n",
    "def clean_word(word_list):\n",
    "\tnew_word_list = []\n",
    "\tfor word in word_list:\n",
    "\t\tfor latex_sensitive in [\"\\\\\", \"%\", \"&\", \"^\", \"#\", \"_\",  \"{\", \"}\"]:\n",
    "\t\t\tif latex_sensitive in word:\n",
    "\t\t\t\tword = word.replace(latex_sensitive, '\\\\'+latex_sensitive)\n",
    "\t\tnew_word_list.append(word)\n",
    "\treturn new_word_list\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv(f'csv/203-csv/585.csv', sep=',', on_bad_lines='warn')\n",
    "# df.columns = ['Team', 'County', 'Wins', 'Years_won']\n",
    "cols = df.columns.tolist()\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the question based on the data below: \"who had the most Silver medals?\". \n",
      "\n",
      "[HEAD]: Rank|Nation|Gold|Silver|Bronze|Total\n",
      "[ROW] 1: 1|Soviet Union|7|3|6|16\n",
      "[ROW] 2: 2|Austria|4|3|4|11\n",
      "[ROW] 3: 3|Finland|3|3|1|7\n",
      "[ROW] 4: 4|Switzerland|3|2|1|6\n",
      "[ROW] 5: 5|Sweden|2|4|4|10\n",
      "[ROW] 6: 6|United States|2|3|2|7\n",
      "[ROW] 7: 7|Norway|2|1|1|4\n",
      "[ROW] 8: 8|Italy|1|2|0|3\n",
      "[ROW] 9: 9|Germany|1|0|1|2\n",
      "[ROW] 10: 10|Canada|0|1|2|3\n",
      "\n",
      "The answer is: ```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import dotenv\n",
    "config = dotenv.dotenv_values(\".env\")\n",
    "openai.api_key = config['OPENAI_API_KEY_ms']\n",
    "# prompt = f\"\"\"\n",
    "# Answer the question based on the data below: \"who had the most silver medals?\". \n",
    "\n",
    "# A selected table: \n",
    "# {table_formater(concise_df)}\n",
    "\n",
    "# The full table is:\n",
    "# {table_formater(df)}\n",
    "\n",
    "# The answer is: ```\n",
    "# \"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "Answer the question based on the data below: \"who had the most Silver medals?\". \n",
    "\n",
    "[HEAD]: Rank|Nation|Gold|Silver|Bronze|Total\n",
    "[ROW] 1: 1|Soviet Union|7|3|6|16\n",
    "[ROW] 2: 2|Austria|4|3|4|11\n",
    "[ROW] 3: 3|Finland|3|3|1|7\n",
    "[ROW] 4: 4|Switzerland|3|2|1|6\n",
    "[ROW] 5: 5|Sweden|2|4|4|10\n",
    "[ROW] 6: 6|United States|2|3|2|7\n",
    "[ROW] 7: 7|Norway|2|1|1|4\n",
    "[ROW] 8: 8|Italy|1|2|0|3\n",
    "[ROW] 9: 9|Germany|1|0|1|2\n",
    "[ROW] 10: 10|Canada|0|1|2|3\n",
    "\n",
    "The answer is: ```\n",
    "\"\"\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-6PRJGDXCwOAim7skbcXyW8xiHs9bW at 0x7fb8e437bae0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"Soviet Union\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1671521198,\n",
       "  \"id\": \"cmpl-6PRJGDXCwOAim7skbcXyW8xiHs9bW\",\n",
       "  \"model\": \"davinci-codex-002-msft\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 2,\n",
       "    \"prompt_tokens\": 233,\n",
       "    \"total_tokens\": 235\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = 'davinci-codex-002-msft'\n",
    "# model = 'text-davinci-002'\n",
    "# model = 'text-davinci-003'\n",
    "\n",
    "openai.Completion.create(   engine=model,\n",
    "                            prompt=prompt,\n",
    "                            max_tokens=128,\n",
    "                            temperature=0,\n",
    "                            top_p=1,\n",
    "                            frequency_penalty=0,\n",
    "                            n=1,\n",
    "                            stream=False,\n",
    "                            stop='```')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15160, 7496]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('Austria')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You have to specify either decoder_input_ids or decoder_inputs_embeds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [140]\u001b[0m, in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m word_cnt:\n\u001b[1;32m     32\u001b[0m     ori_input_ids \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mori_input_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     attentions \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mattentions\n\u001b[1;32m     35\u001b[0m     pred_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(outputs\u001b[38;5;241m.\u001b[39mlogits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py:1435\u001b[0m, in \u001b[0;36mT5Model.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1432\u001b[0m         decoder_attention_mask \u001b[38;5;241m=\u001b[39m decoder_attention_mask\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mfirst_device)\n\u001b[1;32m   1434\u001b[0m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[0;32m-> 1435\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1436\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1437\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1438\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1439\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1440\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1441\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1443\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1444\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1445\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1446\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1447\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1448\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[1;32m   1451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m decoder_outputs \u001b[38;5;241m+\u001b[39m encoder_outputs\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/t5/modeling_t5.py:937\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    936\u001b[0m     err_msg_prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 937\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to specify either \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr_msg_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124minput_ids or \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr_msg_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124minputs_embeds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    939\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    940\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to initialize the model with valid token embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: You have to specify either decoder_input_ids or decoder_inputs_embeds"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Answer the question based on the data below: \"who had the most Silver medals?\". \n",
    "\n",
    "[HEAD]: Rank|Nation|Gold|Silver|Bronze|Total\n",
    "[ROW] 1: 1|Soviet Union|7|3|6|16\n",
    "[ROW] 2: 2|Austria|4|3|4|11\n",
    "[ROW] 3: 3|Finland|3|3|1|7\n",
    "[ROW] 4: 4|Switzerland|3|2|1|6\n",
    "[ROW] 5: 5|Sweden|2|4|4|10\n",
    "[ROW] 6: 6|United States|2|3|2|7\n",
    "[ROW] 7: 7|Norway|2|1|1|4\n",
    "[ROW] 8: 8|Italy|1|2|0|3\n",
    "[ROW] 9: 9|Germany|1|0|1|2\n",
    "[ROW] 10: 10|Canada|0|1|2|3\n",
    "\n",
    "The answer is: \n",
    "\"\"\"\n",
    "# prompt = \"Machine learning with PyTorch can do amazing\"\n",
    "# prompt = \"Machine learning with PyTorch can do amazing\"\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, utils, AutoModelForCausalLM\n",
    "import torch\n",
    "model = 'gpt2'\n",
    "model = 't5-large'\n",
    "utils.logging.set_verbosity_error()  # Suppress standard warnings\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "model = AutoModel.from_pretrained(model, output_attentions=True)\n",
    "\n",
    "predicted = ''\n",
    "word_cnt = 1\n",
    "while word_cnt:\n",
    "    ori_input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    outputs = model(ori_input_ids)\n",
    "    attentions = outputs.attentions\n",
    "    pred_id = torch.argmax(outputs.logits[:, -1, :]).item()\n",
    "    pred_word = tokenizer.decode(pred_id)\n",
    "    # print(\"Predict: \\'\", pred_word, \"\\'\")\n",
    "    predicted += pred_word\n",
    "    prompt += pred_word\n",
    "    word_cnt -= 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 9, 9])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attentions[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 233, 50257])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  198, 33706,   262,  1808,  1912,   319,   262,  1366,  2174,    25,\n",
       "           366,  8727,   550,   262,   749,  7698, 28057, 43634,   220,   198,\n",
       "           198,    58, 37682,  5974, 10916,    91, 46108,    91, 13306,    91,\n",
       "         26766,    91, 18760,  2736,    91, 14957,   198,    58,    49,  3913,\n",
       "            60,   352,    25,   352,    91, 40408,  4479,    91,    22,    91,\n",
       "            18,    91,    21,    91,  1433,   198,    58,    49,  3913,    60,\n",
       "           362,    25,   362,    91, 15160,  7496,    91,    19,    91,    18,\n",
       "            91,    19,    91,  1157,   198,    58,    49,  3913,    60,   513,\n",
       "            25,   513,    91, 18467,  1044,    91,    18,    91,    18,    91,\n",
       "            16,    91,    22,   198,    58,    49,  3913,    60,   604,    25,\n",
       "           604,    91, 10462, 13947,    91,    18,    91,    17,    91,    16,\n",
       "            91,    21,   198,    58,    49,  3913,    60,   642,    25,   642,\n",
       "            91, 10462, 31829,    91,    17,    91,    19,    91,    19,    91,\n",
       "           940,   198,    58,    49,  3913,    60,   718,    25,   718,    91,\n",
       "         17013,  1829,    91,    17,    91,    18,    91,    17,    91,    22,\n",
       "           198,    58,    49,  3913,    60,   767,    25,   767,    91, 21991,\n",
       "          1014,    91,    17,    91,    16,    91,    16,    91,    19,   198,\n",
       "            58,    49,  3913,    60,   807,    25,   807,    91, 45001,    91,\n",
       "            16,    91,    17,    91,    15,    91,    18,   198,    58,    49,\n",
       "          3913,    60,   860,    25,   860,    91, 27079,    91,    16,    91,\n",
       "            15,    91,    16,    91,    17,   198,    58,    49,  3913,    60,\n",
       "           838,    25,   838,    91, 17940,    91,    15,    91,    16,    91,\n",
       "            17,    91,    18,   198,   198,   464,  3280,   318,    25,  7559,\n",
       "            63,   198]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertviz import head_view\n",
    "head_view(attention, tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "t = torch.zeros([len(tokens), len(tokens)]).float()\n",
    "for att in attention:\n",
    "    t += torch.mean(torch.squeeze(att), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 63, 768]), torch.Size([1, 63]))"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state.shape, inputs.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import openai\n",
    "import os\n",
    "import json\n",
    "from gpt3_sandbox.api.gpt import GPT\n",
    "from gpt3_sandbox.api.gpt import Example\n",
    "from pandasql import sqldf\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import dotenv\n",
    "config = dotenv.dotenv_values(\".env\")\n",
    "openai.api_key = config['OPENAI_API_KEY_ms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \\\n",
    "\"\"\"\n",
    "The database schema is as follows:\n",
    "---\n",
    "Table 'artists'\n",
    "Columns: 'id', 'name'\n",
    "Table 'sqlite_sequence'\n",
    "Columns: 'name', 'seq'\n",
    "Table 'albums'\n",
    "Columns: 'id', 'title', 'artist_id'\n",
    "Table 'employees'\n",
    "Columns: 'id', 'last_name', 'first_name', 'title', 'reports_to', 'birth_date', 'hire_date', 'address', 'city', 'state', 'country', 'postal_code', 'phone', 'fax', 'email'\n",
    "Table 'customers'\n",
    "Columns: 'id', 'first_name', 'last_name', 'company', 'address', 'city', 'state', 'country', 'postal_code', 'phone', 'fax', 'email', 'support_rep_id'\n",
    "Table 'genres'\n",
    "Columns: 'id', 'name'\n",
    "Table 'invoices'\n",
    "Columns: 'id', 'customer_id', 'invoice_date', 'billing_address', 'billing_city', 'billing_state', 'billing_country', 'billing_postal_code', 'total'\n",
    "Table 'media_types'\n",
    "Columns: 'id', 'name'\n",
    "Table 'tracks'\n",
    "Columns: 'id', 'name', 'album_id', 'media_type_id', 'genre_id', 'composer', 'milliseconds', 'bytes', 'unit_price'\n",
    "Table 'invoice_lines'\n",
    "Columns: 'id', 'invoice_id', 'track_id', 'unit_price', 'quantity'\n",
    "Table 'playlists'\n",
    "Columns: 'id', 'name'\n",
    "Table 'playlist_tracks'\n",
    "Columns: 'playlist_id', 'track_id'\n",
    "---\n",
    "\n",
    "Generate a valid and syntactically correct SQL query that answers the following question and adheres to the schema listed above: \"What is the count of customers that Steve Johnson supports?\"\n",
    "Generate the SQL step-by-step:\n",
    "1. SELECT * FROM employees AS t1;\n",
    "2. SELECT * FROM employees AS t1 JOIN customers AS t2 ON t2.support_rep_id = t1.id;\n",
    "3. SELECT * FROM employees AS t1 JOIN customers AS t2 ON t2.support_rep_id = t1.id WHERE t1.first_name = \"Steve\" AND t1.last_name = \"Johnson\";\n",
    "Therefore, the SQL query is ```SELECT * FROM employees AS t1 JOIN customers AS t2 ON t2.support_rep_id = t1.id WHERE t1.first_name = \"Steve\" AND t1.last_name = \"Johnson\";```.\n",
    "\n",
    "\n",
    "The database schema is as follows:\n",
    "---\n",
    "Table 'stadium'\n",
    "Columns: 'Stadium_ID', 'Location', 'Name', 'Capacity', 'Highest', 'Lowest', 'Average'\n",
    "Table 'singer'\n",
    "Columns: 'Singer_ID', 'Name', 'Country', 'Song_Name', 'Song_release_year', 'Age', 'Is_male'\n",
    "Table 'concert'\n",
    "Columns: 'concert_ID', 'concert_Name', 'Theme', 'Stadium_ID', 'Year'\n",
    "Table 'singer_in_concert'\n",
    "Columns: 'concert_ID', 'Singer_ID'\n",
    "---\n",
    "Generate a valid and syntactically correct SQL query that answers the following question and adheres to the schema listed above: \"Show the name and the release year of the song by the youngest singer.\".\n",
    "Generate the SQL step-by-step:\"\"\"\n",
    "\n",
    "\n",
    "response = openai.Completion.create(engine='code-davinci-002',\n",
    "                                            prompt=prompt,\n",
    "                                            max_tokens=1024,\n",
    "                                            temperature=0,\n",
    "                                            top_p=1,\n",
    "                                            n=1,\n",
    "                                            stream=False,\n",
    "                                            stop='```.', \n",
    "                                            frequency_penalty=0.7)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \\\n",
    "\"\"\"\n",
    "The database schema is as follows:\n",
    "---\n",
    "Table 'Addresses'\n",
    "Columns: 'address_id', 'line_1_number_building', 'city', 'zip_postcode', 'state_province_county', 'country'\n",
    "Table 'Staff'\n",
    "Columns: 'staff_id', 'staff_address_id', 'nickname', 'first_name', 'middle_name', 'last_name', 'date_of_birth', 'date_joined_staff', 'date_left_staff'\n",
    "Table 'Vehicles'\n",
    "Columns: 'vehicle_id', 'vehicle_details'\n",
    "Table 'Customers'\n",
    "Columns: 'customer_id', 'customer_address_id', 'customer_status_code', 'date_became_customer', 'date_of_birth', 'first_name', 'last_name', 'amount_outstanding', 'email_address', 'phone_number', 'cell_mobile_phone_number'\n",
    "Table 'Customer_Payments'\n",
    "Columns: 'customer_id', 'datetime_payment', 'payment_method_code', 'amount_payment'\n",
    "Table 'Lessons'\n",
    "Columns: 'lesson_id', 'customer_id', 'lesson_status_code', 'staff_id', 'vehicle_id', 'lesson_date', 'lesson_time', 'price'\n",
    "---\n",
    "\n",
    "Generate a valid and syntactically correct SQL query that answers the following question and adheres to the schema listed above: \n",
    "\"What is the total amount of moeny paid by the customer Carole Bernhard?\".\n",
    "SQL: ```\n",
    "SELECT sum(t1.amount_payment)\n",
    "FROM customer_payments AS t1\n",
    "JOIN customers AS t2 ON t1.customer_id = t2.customer_id\n",
    "WHERE t2.first_name = \"Carole\"\n",
    "  AND t2.last_name = \"Bernhard\"\n",
    "```\n",
    "\n",
    "\n",
    "The database schema is as follows:\n",
    "---\n",
    "Table 'stadium'\n",
    "Columns: 'Stadium_ID', 'Location', 'Name', 'Capacity', 'Highest', 'Lowest', 'Average'\n",
    "Table 'singer'\n",
    "Columns: 'Singer_ID', 'Name', 'Country', 'Song_Name', 'Song_release_year', 'Age', 'Is_male'\n",
    "Table 'concert'\n",
    "Columns: 'concert_ID', 'concert_Name', 'Theme', 'Stadium_ID', 'Year'\n",
    "Table 'singer_in_concert'\n",
    "Columns: 'concert_ID', 'Singer_ID'\n",
    "---\n",
    "\n",
    "Generate a valid and syntactically correct SQL query that answers the following question and adheres to the schema listed above: \n",
    "\"Show the name and the release year of the song by the youngest singer.\"\n",
    "SQL:```\"\"\"\n",
    "\n",
    "\n",
    "response = openai.Completion.create(engine='code-davinci-002',\n",
    "                                            prompt=prompt,\n",
    "                                            max_tokens=1024,\n",
    "                                            temperature=0,\n",
    "                                            top_p=1,\n",
    "                                            n=1,\n",
    "                                            stream=False,\n",
    "                                            stop='```', \n",
    "                                            frequency_penalty=0.7)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \\\n",
    "\"\"\"\n",
    "The database schema is as follows:\n",
    "---\n",
    "Table 'Addresses'\n",
    "Columns: 'address_id', 'line_1_number_building', 'city', 'zip_postcode', 'state_province_county', 'country'\n",
    "Table 'Staff'\n",
    "Columns: 'staff_id', 'staff_address_id', 'nickname', 'first_name', 'middle_name', 'last_name', 'date_of_birth', 'date_joined_staff', 'date_left_staff'\n",
    "Table 'Vehicles'\n",
    "Columns: 'vehicle_id', 'vehicle_details'\n",
    "Table 'Customers'\n",
    "Columns: 'customer_id', 'customer_address_id', 'customer_status_code', 'date_became_customer', 'date_of_birth', 'first_name', 'last_name', 'amount_outstanding', 'email_address', 'phone_number', 'cell_mobile_phone_number'\n",
    "Table 'Customer_Payments'\n",
    "Columns: 'customer_id', 'datetime_payment', 'payment_method_code', 'amount_payment'\n",
    "Table 'Lessons'\n",
    "Columns: 'lesson_id', 'customer_id', 'lesson_status_code', 'staff_id', 'vehicle_id', 'lesson_date', 'lesson_time', 'price'\n",
    "---\n",
    "\n",
    "Generate a valid and syntactically correct SQL query that answers the following question and adheres to the schema listed above: \n",
    "\"What is the total amount of moeny paid by the customer Carole Bernhard?\".\n",
    "Generate the SQL step-by-step:\n",
    "1. SELECT sum(t1.amount_payment) FROM customer_payments AS t1;\n",
    "2. SELECT sum(t1.amount_payment) FROM customer_payments AS t1 \n",
    "   JOIN customers AS t2 ON t1.customer_id = t2.customer_id;\n",
    "3. SELECT sum(t1.amount_payment) FROM customer_payments AS t1 \n",
    "   JOIN customers AS t2 ON t1.customer_id = t2.customer_id \n",
    "   WHERE t2.first_name = \"Carole\" AND t2.last_name = \"Bernhard\";\n",
    "Therefore, the SQL query is:```\n",
    "SELECT sum(t1.amount_payment)\n",
    "FROM customer_payments AS t1\n",
    "JOIN customers AS t2 ON t1.customer_id = t2.customer_id\n",
    "WHERE t2.first_name = \"Carole\"\n",
    "  AND t2.last_name = \"Bernhard\"\n",
    "```.\n",
    "\n",
    "The database schema is as follows:\n",
    "---\n",
    "Table 'stadium'\n",
    "Columns: 'Stadium_ID', 'Location', 'Name', 'Capacity', 'Highest', 'Lowest', 'Average'\n",
    "Table 'singer'\n",
    "Columns: 'Singer_ID', 'Name', 'Country', 'Song_Name', 'Song_release_year', 'Age', 'Is_male'\n",
    "Table 'concert'\n",
    "Columns: 'concert_ID', 'concert_Name', 'Theme', 'Stadium_ID', 'Year'\n",
    "Table 'singer_in_concert'\n",
    "Columns: 'concert_ID', 'Singer_ID'\n",
    "---\n",
    "\n",
    "Generate a valid and syntactically correct SQL query that answers the following question and adheres to the schema listed above: \n",
    "\"Show the name and the release year of the song by the youngest singer.\"\n",
    "Generate the SQL step-by-step:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "response = openai.Completion.create(engine='code-davinci-002',\n",
    "                                            prompt=prompt,\n",
    "                                            max_tokens=1024,\n",
    "                                            temperature=0,\n",
    "                                            top_p=1,\n",
    "                                            n=1,\n",
    "                                            stream=False,\n",
    "                                            stop='```.', \n",
    "                                            frequency_penalty=0.7)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Therefore, we use LIP and AJA to represent the simple yet effective and commonly deployed techniques, and perform comparisons with state-of-the-art reinforcement learning-based query optimizers.\n"
     ]
    }
   ],
   "source": [
    "prompt = \\\n",
    "\"\"\"\n",
    "I'm a researcher in Database systems, and I am writing a conference paper. Help me improve the following sentences and highlight the changes.\n",
    "\n",
    "Therefore, we use LIP and AJA to represent the simple but effective and commonly deployed techniques and perform comparisons with SOTA RL-based query optimizers. \"\"\"\n",
    "\n",
    "response = openai.Completion.create(engine='text-davinci-003',\n",
    "                                            prompt=prompt,\n",
    "                                            max_tokens=1024,\n",
    "                                            temperature=0.5,\n",
    "                                            top_p=1,\n",
    "                                            n=1,\n",
    "                                            stream=False,\n",
    "                                            # stop='```.', \n",
    "                                            frequency_penalty=0)\n",
    "print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "DF = pd.read_csv(f'./csv/203-csv/733.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Cyclist</th>\n",
       "      <th>Team</th>\n",
       "      <th>Time</th>\n",
       "      <th>UCI ProTour\\nPoints</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alejandro Valverde (ESP)</td>\n",
       "      <td>Caisse d'Epargne</td>\n",
       "      <td>5h 29' 10\\\",40\"</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Alexandr Kolobnev (RUS)</td>\n",
       "      <td>Team CSC Saxo Bank</td>\n",
       "      <td>s.t.</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Davide Rebellin (ITA)</td>\n",
       "      <td>Gerolsteiner</td>\n",
       "      <td>s.t.</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Paolo Bettini (ITA)</td>\n",
       "      <td>Quick Step</td>\n",
       "      <td>s.t.</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Franco Pellizotti (ITA)</td>\n",
       "      <td>Liquigas</td>\n",
       "      <td>s.t.</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Denis Menchov (RUS)</td>\n",
       "      <td>Rabobank</td>\n",
       "      <td>s.t.</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Samuel Sánchez (ESP)</td>\n",
       "      <td>Euskaltel-Euskadi</td>\n",
       "      <td>s.t.</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Stéphane Goubert (FRA)</td>\n",
       "      <td>Ag2r-La Mondiale</td>\n",
       "      <td>+ 2\\\",5\"</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Haimar Zubeldia (ESP)</td>\n",
       "      <td>Euskaltel-Euskadi</td>\n",
       "      <td>+ 2\\\",3\"</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>David Moncoutié (FRA)</td>\n",
       "      <td>Cofidis</td>\n",
       "      <td>+ 2\\\",1\"</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                   Cyclist                Team             Time  \\\n",
       "0     1  Alejandro Valverde (ESP)    Caisse d'Epargne  5h 29' 10\\\",40\"   \n",
       "1     2   Alexandr Kolobnev (RUS)  Team CSC Saxo Bank             s.t.   \n",
       "2     3     Davide Rebellin (ITA)        Gerolsteiner             s.t.   \n",
       "3     4       Paolo Bettini (ITA)          Quick Step             s.t.   \n",
       "4     5   Franco Pellizotti (ITA)            Liquigas             s.t.   \n",
       "5     6       Denis Menchov (RUS)            Rabobank             s.t.   \n",
       "6     7      Samuel Sánchez (ESP)   Euskaltel-Euskadi             s.t.   \n",
       "7     8    Stéphane Goubert (FRA)    Ag2r-La Mondiale         + 2\\\",5\"   \n",
       "8     9     Haimar Zubeldia (ESP)   Euskaltel-Euskadi         + 2\\\",3\"   \n",
       "9    10     David Moncoutié (FRA)             Cofidis         + 2\\\",1\"   \n",
       "\n",
       "   UCI ProTour\\nPoints  \n",
       "0                  NaN  \n",
       "1                 30.0  \n",
       "2                 25.0  \n",
       "3                 20.0  \n",
       "4                 15.0  \n",
       "5                 11.0  \n",
       "6                  7.0  \n",
       "7                  NaN  \n",
       "8                  NaN  \n",
       "9                  NaN  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"\n",
    "def get_country(s):\n",
    "    return s.split(' ')[-1][1:-1]\n",
    "DF['country'] = DF.apply(lambda x: get_country(x['Cyclist']), axis=1)\"\"\"\n",
    "exec(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Cyclist</th>\n",
       "      <th>Team</th>\n",
       "      <th>Time</th>\n",
       "      <th>UCI ProTour\\nPoints</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alejandro Valverde (ESP)</td>\n",
       "      <td>Caisse d'Epargne</td>\n",
       "      <td>5h 29' 10\\\",40\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ESP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Alexandr Kolobnev (RUS)</td>\n",
       "      <td>Team CSC Saxo Bank</td>\n",
       "      <td>s.t.</td>\n",
       "      <td>30.0</td>\n",
       "      <td>RUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Davide Rebellin (ITA)</td>\n",
       "      <td>Gerolsteiner</td>\n",
       "      <td>s.t.</td>\n",
       "      <td>25.0</td>\n",
       "      <td>ITA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Paolo Bettini (ITA)</td>\n",
       "      <td>Quick Step</td>\n",
       "      <td>s.t.</td>\n",
       "      <td>20.0</td>\n",
       "      <td>ITA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Franco Pellizotti (ITA)</td>\n",
       "      <td>Liquigas</td>\n",
       "      <td>s.t.</td>\n",
       "      <td>15.0</td>\n",
       "      <td>ITA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Denis Menchov (RUS)</td>\n",
       "      <td>Rabobank</td>\n",
       "      <td>s.t.</td>\n",
       "      <td>11.0</td>\n",
       "      <td>RUS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Samuel Sánchez (ESP)</td>\n",
       "      <td>Euskaltel-Euskadi</td>\n",
       "      <td>s.t.</td>\n",
       "      <td>7.0</td>\n",
       "      <td>ESP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Stéphane Goubert (FRA)</td>\n",
       "      <td>Ag2r-La Mondiale</td>\n",
       "      <td>+ 2\\\",5\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Haimar Zubeldia (ESP)</td>\n",
       "      <td>Euskaltel-Euskadi</td>\n",
       "      <td>+ 2\\\",3\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ESP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>David Moncoutié (FRA)</td>\n",
       "      <td>Cofidis</td>\n",
       "      <td>+ 2\\\",1\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FRA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                   Cyclist                Team             Time  \\\n",
       "0     1  Alejandro Valverde (ESP)    Caisse d'Epargne  5h 29' 10\\\",40\"   \n",
       "1     2   Alexandr Kolobnev (RUS)  Team CSC Saxo Bank             s.t.   \n",
       "2     3     Davide Rebellin (ITA)        Gerolsteiner             s.t.   \n",
       "3     4       Paolo Bettini (ITA)          Quick Step             s.t.   \n",
       "4     5   Franco Pellizotti (ITA)            Liquigas             s.t.   \n",
       "5     6       Denis Menchov (RUS)            Rabobank             s.t.   \n",
       "6     7      Samuel Sánchez (ESP)   Euskaltel-Euskadi             s.t.   \n",
       "7     8    Stéphane Goubert (FRA)    Ag2r-La Mondiale         + 2\\\",5\"   \n",
       "8     9     Haimar Zubeldia (ESP)   Euskaltel-Euskadi         + 2\\\",3\"   \n",
       "9    10     David Moncoutié (FRA)             Cofidis         + 2\\\",1\"   \n",
       "\n",
       "   UCI ProTour\\nPoints country  \n",
       "0                  NaN     ESP  \n",
       "1                 30.0     RUS  \n",
       "2                 25.0     ITA  \n",
       "3                 20.0     ITA  \n",
       "4                 15.0     ITA  \n",
       "5                 11.0     RUS  \n",
       "6                  7.0     ESP  \n",
       "7                  NaN     FRA  \n",
       "8                  NaN     ESP  \n",
       "9                  NaN     FRA  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
